{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal 3D Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from mmengine.logging import print_log\n",
    "from mmdet3d.apis import MultiModalityDet3DInferencer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def read_config(path: str):\n",
    "    with open(path) as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "\n",
    "\n",
    "config = read_config('config.yaml')\n",
    "init_config = {'model':config['model'], 'weights':config['weights'], 'device': config['device']}\n",
    "call_config = {'inputs': {'points':config['pcd'], 'img':config['img'], 'infos': config['infos']}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVX-Net (Kitti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk/Research/Thesis/Benchmarks/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: checkpoints/mvxnet_fpn_dv_second_secfpn_8xb2-80e_kitti-3d-3class-8963258a.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for pts_middle_encoder.conv_input.0.weight: copying a param with shape torch.Size([16, 3, 3, 3, 128]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 128, 16]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer1.0.0.weight: copying a param with shape torch.Size([16, 3, 3, 3, 16]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 16, 16]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer2.0.0.weight: copying a param with shape torch.Size([32, 3, 3, 3, 16]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 16, 32]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer2.1.0.weight: copying a param with shape torch.Size([32, 3, 3, 3, 32]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 32, 32]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer2.2.0.weight: copying a param with shape torch.Size([32, 3, 3, 3, 32]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 32, 32]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer3.0.0.weight: copying a param with shape torch.Size([64, 3, 3, 3, 32]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 32, 64]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer3.1.0.weight: copying a param with shape torch.Size([64, 3, 3, 3, 64]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 64, 64]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer3.2.0.weight: copying a param with shape torch.Size([64, 3, 3, 3, 64]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 64, 64]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer4.0.0.weight: copying a param with shape torch.Size([64, 3, 3, 3, 64]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 64, 64]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer4.1.0.weight: copying a param with shape torch.Size([64, 3, 3, 3, 64]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 64, 64]).\n",
      "size mismatch for pts_middle_encoder.encoder_layers.encoder_layer4.2.0.weight: copying a param with shape torch.Size([64, 3, 3, 3, 64]) from checkpoint, the shape in current model is torch.Size([3, 3, 3, 64, 64]).\n",
      "size mismatch for pts_middle_encoder.conv_out.0.weight: copying a param with shape torch.Size([128, 3, 1, 1, 64]) from checkpoint, the shape in current model is torch.Size([3, 1, 1, 64, 128]).\n",
      "05/06 20:01:46 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet3d\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet3d\" is a correct scope, or whether the registry is initialized.\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk/.local/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "inferencer = MultiModalityDet3DInferencer(**init_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30114819208946fabfeff51968dc74f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/bk/Research/Thesis/Benchmarks/mmdetection3d/mmdet3d/models/layers/fusion_layers/coord_transform.py:40: \n",
       "UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or \n",
       "sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  torch.tensor(img_meta['pcd_rotation'], dtype=dtype, device=device)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/bk/Research/Thesis/Benchmarks/mmdetection3d/mmdet3d/models/layers/fusion_layers/coord_transform.py:40: \n",
       "UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or \n",
       "sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
       "  torch.tensor(img_meta['pcd_rotation'], dtype=dtype, device=device)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/bk/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: \n",
       "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at\n",
       "../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
       "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/bk/miniconda3/envs/openmmlab/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: \n",
       "torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at\n",
       "../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
       "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'labels_3d': [],\n",
       "   'scores_3d': [],\n",
       "   'bboxes_3d': [],\n",
       "   'box_type_3d': 'LiDAR'}],\n",
       " 'visualization': []}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencer(**call_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mmdet3d.apis.inferencers.multi_modality_det3d_inferencer.MultiModalityDet3DInferencer object at 0x7f3153b9caf0>\n"
     ]
    }
   ],
   "source": [
    "print(inferencer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVX-Net (nuScenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVX-Net (Waymo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEV-Fusion (Kitti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEV-Fusion (nuScenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEV-Fusion (Waymo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
